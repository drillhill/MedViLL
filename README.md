# Diseases Diagnosis System  
### Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training  

This project implements the paper **"MedViLL: Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training"** in a **Diseases Diagnosis System**. The system leverages multi-modal learning techniques to enhance the understanding and generation of medical image-text data.  

## ğŸ“„ Paper  
You can read the original paper here:  
**[MedViLL: Multi-modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training](https://arxiv.org/abs/2105.11333)**  

## ğŸ“‚ Implementation  
The official implementation of the MedViLL model. You can explore the original codebase here:  
**[MedViLL GitHub Repository](https://github.com/SuperSupermoon/MedViLL/tree/master)**  

## ğŸ“‘ Report  
For more details on our implementation and findings, check out our project report:  
**[Google Drive Report](https://drive.google.com/drive/folders/18nfEA7BvSM4TmsMMGA2ZZw_hWMLxGK59?usp=sharing)**  

## ğŸš€ Features  
- Multi-modal learning using medical images and text  
- Vision-language pre-training approach  
- Disease diagnosis and medical report generation  

## ğŸ“Œ How to Use  
Run the code inside the notebook [**medvill-finetune.ipynb**](medvill-finetune.ipynb)

## ğŸ¤ Contributors  
- Phan Nguyen Phuong
- Vu Minh Thu
- Phung Doan Khoi
